```{r, echo=FALSE, include=FALSE}
library("rSFFreader")
```

Pyrosequencing PreProcessing Report File for `r basefilename`  -- Microbial Amplicons
========================================================

Summary
--------------------------------------------------------
--------------------------------------------------------

Raw unclipped Roche 454 pyrosequence reads are cleaned, taxonomically assigned and filtered in
the following manner. Raw SFF files are read directly into the R statistical programming
language using the R package rSFFreader (http://bioconductor.org/packages/2.11/bioc/html/rSFFreader.html, version `r packageVersion("rSFFreader")`), Roche quality clip points are identified and recorded; however, full sequence
reads (unclipped) are used for the identification of Roche 454 adapters, barcodes and amplicon
primers sequence using Cross Match (version `r cross_match_ver`, parameters: min matches=`r cross_match_minmatch`, min
score=`r cross_match_minscore` and -tags) from the phred/phrap/consed application suite. Cross Match alignment information
is then read into R and processed to identify alignment quality, directionality, barcode
assignment, and new read clip points. Base quality clipping was performed using the application
Lucy (version `r lucy_ver`, parameters: max average error=`r lucy_max_avg_error`, max error at ends=
`r lucy_max_error_at_ends`, minimum=0). We then align the clipped reads to the silva bacterial sequence database
using mothur (version `r mothur_ver`). Alignment end points are identified and used in subsequent filtering. Sequence reads
were filtered to only those that met the following criteria: 

Read quality metrics
1. max hamming distance of barcode = `r maxhammingdisttag`; 
2. maximum number of matching error to forward primer sequences = `r maxforwardprimererrors`; 
3. had < `r maxNs` ambiguous bases (Ns); - After Lucy clipping however, no Ns occur;
4. had < `r maxhomopol`bp homopolymer run in sequence; 

Alignment metrics
5. read alignment started within the first `r align_length_max_error`bp;
6. read alignment length is within `r align_length_max_error`bp of read length;
7. read must align in reverse (3' -> 5');

8. sequence is at least `r minlength`bp in length and no greater than `r maxlength`bp in length; 

The RDP Bayesian classifier is used to assign sequences to phylotypes (RDP `r rdp_ver`). Reads are assigned to the first RDP level with a bootstrap score >=50.

Adapter, Barcode and Primer Identification
--------------------------------------------------------
--------------------------------------------------------

### Basic Read Information
Total Number of Reads in SFF file:`r length(fq)`

Mean length before Roche Right Clip: `r signif(mean(ReadData$RawLength),3)`

Median length before Roche Right Clip: `r signif(median(ReadData$RawLength),3)`

Mean length after Roche Right Clip: `r signif(mean(ReadData$RocheLength),3)`

Median length after Roche Right Clip: `r signif(median(ReadData$RocheLength),3)`

```{r echo=FALSE, fig.align='center',fig.width=9,fig.height=4}
hist(ReadData$RawLength, breaks=200, xlab="Read Length", main="Raw Length")    
hist(ReadData$RocheLength, breaks=200, xlab="Read Length", main="Roche Clipped Length")    
```

### Primer identification using Cross_Match and primer sequences
--------------------------------------------------------
```{r echo=FALSE}
cross_match_call
```

#### Cross match adapter + primer matches (5' and 3' ends) with cooresponding alignment scores
```{r echo=FALSE, fig.align='center',fig.width=9,fig.height=4}
plot(cm_out$read_start[cm_out$FC=="F"],cm_out$score[cm_out$FC=="F"], main="Foward Match",xlab="basepair position",ylab="score")
plot(cm_out$read_start[cm_out$FC=="C"],cm_out$score[cm_out$FC=="C"], main="Reverse Match", xlab="basepair position",ylab="score")
```

Number of 5' matches found: `r table(factor(cm_out$FC,levels=c("C","F")))[2]`

Number of 3' matches found: `r table(factor(cm_out$FC,levels=c("C","F")))[1]`


#### Barcodes Identified
```{r echo=FALSE, fig.align='center', fig.width=18, fig.height=8}
par(mar=c(8,4,1,1)+0.1)
barplot(table(ReadData$Barcode),las=2,cex.names=0.3,xlab="", ylab="Number of reads",main="Distribution of Barcodes")
mtext("Barcode ID", side=1,line=6.5)
```

Reads with Barcode found : `r table(!is.na(ReadData$Barcode))[2]`
#### Barcode and 3' Primer Errors
```{r echo=FALSE, fig.align='center',fig.width=9,fig.height=4}
barplot(table(ReadData$Barcode_Err,useNA="always")/length(fq)*100,ylim=c(0,100),main="Barcode Errors",xlab="Number of errors",ylab="Percent of reads")
barplot(table(ReadData$FP_Err,useNA="always")/length(fq)*100,ylim=c(0,100),main="5' Primer Errors",xlab="Number of errors",ylab="Percent of reads")
```

Total Forward Primer Errors <= `r maxforwardprimererrors` :: Reads meeting that criteria: `r table(ReadData$FP_Err <= maxforwardprimererrors)[2]`

Tag Max Hamming Distance from Target <= `r maxhammingdisttag` :: Reads meeting that criteria: `r table(ReadData$Barcode_Err <= maxhammingdisttag)[2]`
#### 3' Primers found 
```{r echo=FALSE}
as.data.frame(table(ReadData$Primer_3prime,useNA="always"))
```

### Trimming low quality sequence using Lucy
--------------------------------------------------------
```{r echo=FALSE}
lucy_call
```

```{r echo=FALSE, fig.align='center',fig.width=9,fig.height=4}
hist(ReadData$LucyLC - ReadData$AdapterLC,breaks=200,main="Histogram of Lucy trimming (5' end)", xlab="Number of bases trimmed")
hist(ReadData$AdapterRC - ReadData$LucyRC,breaks=200,main="Histogram of Lucy trimming (3' end)", xlab="Number of bases trimmed")
```

Mean number of bases removed by Lucy clipping: `r signif(mean(ReadData$AdapterLength-ReadData$LucyLength),3)`

Median number of bases removed by Lucy clipping: `r signif(median(ReadData$AdapterLength-ReadData$LucyLength),3)`

#### Histogram of read cuts
```{r echo=FALSE, fig.align='center', fig.width=8,fig.height=8}
d <- density(ReadData$RawLength)
d2 <- density(ReadData$RocheLength)
d3 <- density(ReadData$AdapterLength)
d4 <- density(ReadData$LucyLength)
# 
plot(d, main="histogram of read lengths")
lines(d2,col="red")
lines(d3,col="green")
lines(d4,col="orange")
legend("topright",legend=c("Raw","Roche","Primer Trimmed","Lucy Trimmed"),pch=4,text.col=c("black","red","green","orange"),col=c("black","red","green","orange"))
```

Mothur alignment to reference database
--------------------------------------------------------
--------------------------------------------------------
#### Read Alignment locations to regerence
```{r echo=FALSE, fig.align='center', fig.width=9, fig.height=4}
hist(align.report$TemplateEnd,breaks=500)
```

RDP classification
--------------------------------------------------------
--------------------------------------------------------
#### Classification by Alignment location
```{r echo=FALSE, fig.align='center', fig.width=18, fig.height=8}
boxplot(align.report$TemplateEnd[expand][ReadData$keep] ~ rdp.lucy$V18[expand][ReadData$keep],xaxt="n",xlab="",main="Taxa my alignmenet location",ylab="basepair position",xlab="")
axis(1,labels=FALSE)
labels <- sort(unique(rdp.lucy$V18[expand][ReadData$keep]))
text(1:length(labels), par("usr")[3] - 0.50, srt = 90, adj = 1, cex=0.5,
     labels = labels, xpd = TRUE)
```

#### Frequency of top 20 identified taxa > 1%
```{r echo=FALSE, fig.align='center', fig.width=12}
taxa_tb <- table(rdp.lucy$V18[expand][ReadData$keep])/sum(ReadData$keep)*100
par(mar=c(5,8,4,1)+0.1)
barplot(taxa_tb[which(taxa_tb >= 1)],horiz=TRUE,las=2,xlim=c(0,100),main="Common Taxa",xlab="Percent",ylab="")
```

Filtering Reads
--------------------------------------------------------
--------------------------------------------------------
#### Filtered statistics
```{r echo=FALSE, fig.align='center', fig.width=12}
par(mar=c(5,10,4,2)+0.1)
barplot(c('Forward primer error'=sum(qual_FP_err)/length(qual_FP_err)*100,
          'Barcode error'=sum(qual_hamm_dist)/length(qual_hamm_dist)*100,
          'N bases'=sum(qual_maxN)/length(qual_maxN)*100,
          'Homopolymer count'=sum(qual_homoPrun)/length(qual_homoPrun)*100,
          'Align start dist'=sum(align_start_error)/length(align_start_error)*100,
          'Align length dist'=sum(align_length_error)/length(align_length_error)*100,
          'Align reverse match'=sum(rdp_flip)/length(rdp_flip)*100,
          'Minimum length'=sum(len_min)/length(len_min)*100,
          'Maximum length'=sum(len_max)/length(len_max)*100,
          'All Filter'=sum(ReadData$keep)/length(ReadData$keep)*100),horiz=TRUE,las=2,xlim=c(0,100),xlab="Percentage Pass",main="Filter statistics")
```

Final number of reads passing filter: `r sum(ReadData$keep)` (`r sum(ReadData$keep)/length(ReadData$keep)*100`%)

Total number of unique reads: `r length(unique(ReadData$LucyUnique[ReadData$keep]))`



Appendix - Adapters Screened for
--------------------------------------------------------
--------------------------------------------------------
```{r echo=FALSE, as.is=TRUE}
library(xtable)
print(xtable(data.frame(Length=width(screen),Sequence=as.character(screen))),type="html")
```

SessionInfo
--------------------------------------------------------
--------------------------------------------------------
```{r echo=FALSE}
sessionInfo()
```

Report Generated by Matt Settles, Institute for Bioinformatics and Evolutionary STudies (IBEST) (c) 2012